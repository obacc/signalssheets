# ============================================================================
# POLYGON PIPELINE AUTOMATION - CONFIGURATION
# ============================================================================
# Copy this file to .env and fill in the values
# Usage: source automation/config/.env

# GCP Project Configuration
export PROJECT_ID="sunny-advantage-471523-b3"
export REGION="us"
export LOCATION="US"

# BigQuery Configuration
export DATASET="market_data"
export STAGING_TABLE="stg_prices_polygon_raw"
export DESTINATION_TABLE="Prices"
export STORED_PROCEDURE="sp_merge_polygon_prices"

# GCS Configuration
export BUCKET_NAME="ss-bucket-polygon-incremental"
export BUCKET_PATH="polygon/daily"
export BUCKET_URI="gs://${BUCKET_NAME}/${BUCKET_PATH}"

# Scheduling Configuration
export RUN_HOUR="1"                    # 1 AM
export RUN_MINUTE="0"                  # :00
export TIMEZONE="America/Chicago"      # Central Time
export CRON_SCHEDULE="0 1 * * *"      # Daily at 1:00 AM

# Data Processing Configuration
export DAYS_WINDOW=30                  # Default lookback window for queries
export MAX_BAD_RECORDS=100             # Maximum bad records allowed in load
export WRITE_DISPOSITION="WRITE_APPEND" # WRITE_APPEND | WRITE_TRUNCATE
export SOURCE_FORMAT="PARQUET"         # File format in GCS

# Backfill Configuration
export BACKFILL_BATCH_SIZE=5           # Process N dates at a time
export BACKFILL_DELAY_SECONDS=5        # Delay between batches

# Monitoring Configuration
export ALERT_EMAIL="your-email@example.com"
export HEALTHCHECK_LOOKBACK_DAYS=2     # Check last N days
export LOG_LEVEL="INFO"                # DEBUG | INFO | WARN | ERROR

# Service Account (for scripts)
export SERVICE_ACCOUNT_KEY_PATH="/path/to/service-account-key.json"
export SERVICE_ACCOUNT_EMAIL="claudecode@sunny-advantage-471523-b3.iam.gserviceaccount.com"

# DTS Service Account (Data Transfer Service)
# Pattern: service-{PROJECT_NUMBER}@gcp-sa-bigquerydatatransfer.iam.gserviceaccount.com
export DTS_SERVICE_ACCOUNT="service-YOUR_PROJECT_NUMBER@gcp-sa-bigquerydatatransfer.iam.gserviceaccount.com"

# Cost Control
export ENABLE_COST_CONTROLS=true
export MAX_BYTES_BILLED="10737418240"  # 10 GB limit per query

# Dry Run Mode (set to false to execute for real)
export DRY_RUN=true

# ============================================================================
# DERIVED VARIABLES (DO NOT EDIT)
# ============================================================================
export FULL_STAGING_TABLE="${PROJECT_ID}:${DATASET}.${STAGING_TABLE}"
export FULL_DESTINATION_TABLE="${PROJECT_ID}:${DATASET}.${DESTINATION_TABLE}"
export FULL_STORED_PROCEDURE="${PROJECT_ID}:${DATASET}.${STORED_PROCEDURE}"
